{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob as gb\n",
    "import pandas as pd\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import json\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename='newlog.log', mode='a')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "def extract_csvdata():\n",
    "    try:\n",
    "        csvfiles=gb.glob('C:/Users/User/source/*.csv')\n",
    "        CsvDf=[]\n",
    "        for files in csvfiles:\n",
    "            Df=pd.read_csv(files)\n",
    "            CsvDf.append(Df)\n",
    "\n",
    "        Finaldf=pd.concat(CsvDf,ignore_index=True)\n",
    "        logger.info('Data extracted from csv files')\n",
    "        return Finaldf\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f'Error in Extracting data from csv files:{e}')\n",
    "        raise\n",
    "\n",
    "def extract_Jsondata():\n",
    "    try:\n",
    "        jsondf=[]\n",
    "        Jfiles=gb.glob('C:/Users/User/source/*.json')\n",
    "        for file in Jfiles:\n",
    "            Df=pd.read_json(file,lines=True)\n",
    "            jsondf.append(Df)\n",
    "\n",
    "        finaljsondf=pd.concat(jsondf,ignore_index=True)\n",
    "        logger.info('Data extracted from json files')\n",
    "        return(finaljsondf)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f'Error in Extracting data from json files:{e}')\n",
    "        raise\n",
    "\n",
    "def extract_xmldata():\n",
    "        try:\n",
    "            xmlfiles = gb.glob('C:/Users/User/source/*.xml')\n",
    "            xmldf = []\n",
    "            for file in xmlfiles:\n",
    "                tree = et.parse(file)\n",
    "                root = tree.getroot()\n",
    "                data = []\n",
    "                for elem in root:\n",
    "                        record = {}\n",
    "                        for child in elem:\n",
    "                                record[child.tag] = child.text\n",
    "                        data.append(record)\n",
    "                Df = pd.DataFrame(data)\n",
    "                xmldf.append(Df)\n",
    "            finalxmldf= pd.concat(xmldf, ignore_index=True)\n",
    "            return finalxmldf\n",
    "        except Exception as e:\n",
    "            logger.error(f'Error in Extracting data from xml files:{e}')\n",
    "            raise\n",
    "        \n",
    "\n",
    "def Combine_dfs():\n",
    "     try:\n",
    "        csv_df=extract_csvdata()\n",
    "        json_df=extract_Jsondata()\n",
    "        xml_df=extract_xmldata()\n",
    "        sdf=[csv_df,json_df,xml_df]\n",
    "        cdf=pd.concat(sdf,ignore_index=True)\n",
    "        logger.info('All data frames combined successfully')\n",
    "        return cdf\n",
    "     except Exception as e:\n",
    "        logger.error(f'Error in combining all data farmes:{e}')\n",
    "        raise\n",
    "     \n",
    "        \n",
    "\n",
    "def transform_data(Df):\n",
    "    try:\n",
    "        Df['height'] = pd.to_numeric(Df['height'])\n",
    "        Df['HeightsinMeters']=Df['height']*0.3048\n",
    "        Df['weight'] = pd.to_numeric(Df['weight'])\n",
    "        Df['WeightsinKgs']=Df['weight']*0.453592\n",
    "        logger.info('Data transformed successfully')\n",
    "        return(Df)\n",
    "    except Exception as e:\n",
    "        logger.error(f'Error transforming data :{e}')\n",
    "        raise\n",
    "\n",
    "def load_data(Df,combinedfile1):\n",
    "    try:\n",
    "        Df.to_csv(combinedfile1,index=False)\n",
    "        logger.info('Data Loading is successful')\n",
    "    except Exception as e:\n",
    "        logger.error(f'Error in Loading data :{e}')\n",
    "        raise\n",
    "\n",
    "def etl_process():\n",
    "   # try:\n",
    "\n",
    "        #input_path='C:/Users/User/source'\n",
    "        Output_path='C:/Users/User/source/combinedfile.csv'\n",
    "        data =Combine_dfs()\n",
    "        T_data=transform_data(data)\n",
    "        load_data(T_data,Output_path)\n",
    "        logger.info('ETL process completed successfully')\n",
    "    #except Exception as e:\n",
    "       # logger.error(f'ETL process failed :{e}')\n",
    "        #raise\n",
    "\n",
    "if __name__=='__main__':\n",
    "    etl_process()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
